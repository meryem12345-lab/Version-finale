# üìò GRAND GUIDE : ANATOMIE DU PROJET LUNG CANCER PREDICTION

Ce document d√©cortique chaque √©tape du cycle de vie de notre projet de Data Science. Il est con√ßu pour expliquer non seulement *ce que* nous avons fait, mais *pourquoi* nous l'avons fait, en passant du niveau "observateur" au niveau "ing√©nieur".

---

## 1. Le Contexte M√©tier et la Mission

### Le Probl√®me (Business Case)
Le cancer du poumon reste l'une des causes majeures de mortalit√©. Souvent, le diagnostic tombe trop tard.
* **Objectif :** Cr√©er un syst√®me intelligent capable d'√©valuer le **Niveau de Risque** (Faible, Moyen, √âlev√©) d'un patient en fonction de son hygi√®ne de vie et de son environnement.
* **L'Enjeu critique :** Nous ne sommes pas dans une simple r√©ponse Oui/Non, mais dans une gradation de l'urgence.
    * **Le Faux N√©gatif Critique :** Classer un patient √† risque "√âlev√©" en "Faible". C'est l'erreur fatale : le patient ne re√ßoit pas de traitement et la maladie progresse.
    * **L'objectif de l'IA :** Maximiser la sensibilit√© sur la classe "High" pour ne rater aucun cas grave.

### Les Donn√©es (L'Input)
Nous utilisons un jeu de donn√©es cliniques complexe.
* **X (Features) :** 23 caract√©ristiques. Ce ne sont pas des images, mais des donn√©es tabulaires incluant des facteurs comportementaux (Tabagisme, Alcool), environnementaux (Pollution, Risques pro) et symptomatiques (Toux, Douleurs thoraciques).
* **y (Target) :** Une variable ordinale √† 3 niveaux : `Low`, `Medium`, `High`.

---

## 2. Analyse Approfondie : Pr√©traitement (Data Wrangling)

Avant de pouvoir apprendre, la machine doit pouvoir "lire" les donn√©es.

### Le Probl√®me de la Langue
Les algorithmes math√©matiques (comme les r√©seaux de neurones ou le Boosting) ne comprennent pas les mots "Low" ou "High". Ils ne comprennent que les vecteurs num√©riques.

### La M√©canique de l'Encodage (Label Encoding)
Nous avons transform√© la r√©alit√© qualitative en r√©alit√© quantitative :
1.  **La Traduction :** La colonne cible `Level` a √©t√© convertie.
    * `Low` devient **0**
    * `Medium` devient **1**
    * `High` devient **2**
2.  **L'impact :** Cela permet au mod√®le de comprendre une hi√©rarchie (2 est "plus grand" que 0, donc le risque est plus √©lev√©).

---

## 3. Analyse Approfondie : M√©thodologie (Split)

### Le Concept : La Garantie de G√©n√©ralisation
Le but du Machine Learning n'est pas de *m√©moriser* le dossier m√©dical des patients pass√©s, mais de *g√©n√©raliser* pour diagnostiquer les futurs patients.

### La S√©paration 80/20
Nous avons scind√© notre univers en deux mondes parall√®les :
1.  **Le Monde d'Entra√Ænement (80%) :** Le mod√®le y vit, √©tudie les dossiers, fait des erreurs et se corrige. Il conna√Æt les r√©ponses.
2.  **Le Monde de Test (20%) :** C'est l'examen final. Le mod√®le re√ßoit les donn√©es de patients qu'il n'a *jamais vus*. On lui cache la r√©ponse (le niveau de cancer r√©el) et on compare sa pr√©diction √† la r√©alit√©.
    * *Note Expert :* Si le mod√®le est excellent en entra√Ænement mais mauvais en test, on dit qu'il fait de l'**Overfitting** (il a appris par c≈ìur sans comprendre la logique m√©dicale).

---

## 4. FOCUS TH√âORIQUE : La Puissance du XGBoost & Deep Learning üöÄ

Pourquoi avons-nous obtenu des r√©sultats sup√©rieurs aux m√©thodes classiques ?

### A. La Limite des Mod√®les Simples
Une r√©gression logistique simple trace une ligne droite pour s√©parer les groupes. Or, la biologie est complexe : un patient jeune qui fume peut avoir le m√™me risque qu'un patient √¢g√© qui ne fume pas. Les fronti√®res ne sont pas lin√©aires.

### B. L'Approche "Ensemble" (Gradient Boosting)
Le mod√®le **XGBoost** (utilis√© dans ce projet) fonctionne sur le principe de l'am√©lioration continue :
1.  Il cr√©e un premier arbre de d√©cision (un "m√©decin junior") qui fait un diagnostic.
2.  Il regarde les patients sur lesquels ce premier arbre s'est tromp√©.
3.  Il cr√©e un deuxi√®me arbre focalis√© *uniquement* sur la correction des erreurs du premier.
4.  Il r√©p√®te ce processus des centaines de fois.
* **R√©sultat :** Une arm√©e de mod√®les sp√©cialis√©s qui corrigent mutuellement leurs faiblesses, offrant une pr√©cision redoutable.

### C. L'Approche Neuronale (Deep Learning)
Nous avons aussi test√© un **CNN (R√©seau de Neurones)**. Contrairement aux arbres qui posent des questions (Oui/Non), le r√©seau de neurones broie les donn√©es √† travers des couches math√©matiques, cherchant des motifs non-lin√©aires invisibles √† l'≈ìil humain entre les sympt√¥mes et la maladie.

---
<img width="1732" height="495" alt="t√©l√©chargement (2)" src="https://github.com/user-attachments/assets/fe2b7f57-4359-48b4-9b5f-d0fce90dc3d6" />

## 5. Analyse Approfondie : √âvaluation (L'Heure de V√©rit√©)

Comment interpr√©ter notre score de **100% d'Accuracy** ?

### A. La Matrice de Confusion Multiclasse
Au lieu d'un simple carr√© (2x2), nous avons une grille (3x3) pour les classes 0, 1 et 2.
* **La Diagonale du Succ√®s :** Tous nos patients se trouvent sur la diagonale (ex: Pr√©dit High | R√©el High).
* **L'Absence d'Erreurs Hors-Diagonale :** Le mod√®le n'a jamais confondu un "Low" avec un "High".
<img width="1615" height="1357" alt="t√©l√©chargement (1)" src="https://github.com/user-attachments/assets/8519a9a1-a2f4-48ad-add7-41d2714ea059" />

### B. Pr√©cision vs Rappel (Le Duo de Choc)
Dans notre cas, les deux m√©triques sont √† 1.00 (100%), ce qui est l'id√©al th√©orique.
1.  **Pr√©cision (Precision) :** "Quand l'IA dit que c'est grave, est-ce vraiment grave ?"
    * Ici : 100%. Fiabilit√© totale de l'alerte.
2.  **Rappel (Recall) :** "Est-ce que l'IA a d√©tect√© TOUS les cas graves ?"
    * Ici : 100%. Aucun patient √† risque √©lev√© n'est pass√© √† travers les mailles du filet.

### üí° Le Coin de l'Expert (Scep<img width="563" height="512" alt="t√©l√©chargement" src="https://github.com/user-attachments/assets/562f2c94-a7f4-4a47-89e1-00153443f5e6" />
ticisme Scientifique)
Obtenir 100% de pr√©cision sur le jeu de test est extr√™mement rare en conditions r√©elles (donn√©es hospitali√®res bruit√©es).
* **Hypoth√®se 1 :** Le dataset est "trop propre" ou synth√©tique.
* **Hypoth√®se 2 :** Certaines variables (features) sont trop corr√©l√©es √† la cible (ex: si une colonne "Stade du cancer" √©tait pr√©sente dans les features, elle donnerait la r√©ponse imm√©diatement). C'est ce qu'on appelle une **Data Leakage**.
* **Conclusion :** Le mod√®le est techniquement parfait sur ces donn√©es, mais une validation externe sur de nouvelles donn√©es hospitali√®res serait n√©cessaire pour confirmer sa robustesse en production.
